% Created 2020-12-27 Sun 23:59
% Intended LaTeX compiler: pdflatex
\documentclass[sigconf,natbib,screen=true,review=true,anonymous]{acmart}

% We'll get the submission number fro the submission system
\acmSubmissionID{848}

\input{packages}
\input{definitions}
\input{authors}
\input{meta}

\begin{document}

\title[Confusion Matrix Metrics as Losses for Multilabel Classification]{Confusion Matrix Metrics as Losses for \\ Multilabel Classification with Unknown Label Counts}

  % SIMPUL: A Loss Framework to Learn Abstract Labels from Abstract Representations: Single-Instance Multiclass Multilabel Prediction with Unknown Label Count}

\begin{abstract}

Multiclass multilabel classification refers to the task of attributing labels to examples. A particular challenging setting is when both the number of labels for each example is unknown a priori and the example must be consumed in its entirety to be labeled. We refer to this problem setting as Full-Instance, Multilabel Prediction for Unknown Label count (FIMPUL). Current approaches to tackle FIMPUL problems tend to re-frame the problem as a multiclass unilabel classification problem. Two commonly used approaches are (i) optimizing for variations of the traditional cross-entropy loss (the fit-data-to-algorithm approach), or (ii) adapt existing algorithms to the problem at hand (the fit-algorithm-to-data approach).

We take a design-algorithm-for-data approach tailored specifically for the FIMPUL problem and propose a new framework (CoMMaL) for loss functions based on confusion matrix metrics. With CoMMaL, we propose smooth surrogates to confusion matrix metrics that are decomposable for optimization methods such as Stochastic Gradient Descent. Within the CoMMaL framework, we specifically evaluate the effectiveness of sigmoidF1, a smooth surrogate F1 loss, on both text and image data. We embed sigmoidF1 in a classification head that is attached to state-of-the-art pretrained neural networks MobileNetV2 and DistilBERT.

Our experiments show that sigmoidF1 outperforms other existing loss functions in four datasets on several metrics. These results show the effectiveness of using traditional inference-time metrics as loss function at training time.

% \mdr{Multilabel classification is the task of classifying XXX.}
% \mdr{In multilabel classification with unknown label counts we do not know XXX.}
% \mdr{Multilabel classification with unknown label counts are very common in IR.}
% \mdr{Current approaches to Multilabel classification with unknown label counts are characterized by XXX and suffer from YYY.}
% \mdr{We propose XXX to address Multilabel classification with unknown label counts.}
% \mdr{We evaluate our proposal on XXX.}
% \mdr{We find XXX.}
% \mdr{Broader implications.}
\if0
Multilabel classification is a common task when learning from text, image, or sound. However, few optimization frameworks are tailored towards learning multiple abstract labels for an entire text, image, or sound. State of the art models for image and text, of the CNN and BERT family respectively, are often benchmarked on multiclass multilabel datasets, but still use loss functions adapted to a multiclass unilabel situation (i.e. variations of cross-entropy losses).

When the number of ground-truth labels varies over each example as is commonly the case in multilabel classification, these losses produce unit-interval results that require a sophisticated thresholding regime (at training or at inference time) to predict both label prediction propensity and label count.

Since certain confusion matrix metrics usually already fulfill that goal at inference time, we propose decomposable surrogates for gradient descent at training time. We illustrate the solution with \emph{sigmoidF1}: a decomposable surrogate F1 score that introduces smooth thresholding. We are able to demonstrate its performance on efficient versions of the state of the art models (DistilBert and MobileNetV2). For a fair assessment of the proposed loss function, we avoid datasets that would benefit from a two stage modeling procedure (object / expression / segment detection followed by classification) and instead turn to datasets, where the whole example is predictive of a label.
\fi
\end{abstract}


\maketitle

\acresetall

\input{sections/01-introduction}
\input{sections/02-background}
\input{sections/03-method}
\input{sections/04-experimental-setup}
\input{sections/05-experimental-results}
\input{sections/06-related-work}
\input{sections/07-conclusions}

\section*{Reproducibility}
% To facilitate the reproducibility of the reported results, t
This work only made use of publicly available data and our experimental implementation is publicly available at ...

\begin{acks}
 This work was supported by many people.
 All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
