% Created 2020-12-27 Sun 23:59
% Intended LaTeX compiler: pdflatex
\documentclass[sigconf,natbib,screen=true,review=true,anonymous]{acmart}

% We'll get the submission number fro the submission system
\acmSubmissionID{848}

\input{packages}
\input{definitions}
\input{authors}
\input{meta}

\begin{document}

\title{Towards confusion matrix metrics as losses}

  % SIMPUL: A Loss Framework to Learn Abstract Labels from Abstract Representations: Single-Instance Multiclass Multilabel Prediction with Unknown Label Count}

\begin{abstract}
  Multilabel classification is a common task when learning from text, image, or sound. However, few optimization frameworks are tailored towards learning multiple abstract labels for an entire text, image, or sound. State of the art models for image and text, of the CNN and BERT family respectively, are often benchmarked on multiclass multilabel datasets, but still use loss functions adapted to a multiclass unilabel situation (i.e. variations of cross-entropy losses). When the number of ground-truth labels varies over each example as is commonly the case in multilabel classification, these losses produce unit-interval results that require a sophisticated thresholding regime (at training or at inference time) to predict both label prediction propensity and label count. Since certain confusion matrix metrics usually already fulfill that goal at inference time, we propose decomposable surrogates for gradient descent at training time. We illustrate the solution with \emph{sigmoidF1}: a decomposable surrogate F1 score that introduces smooth thresholding. We are able to demonstrate its performance on efficient versions of the state of the art models (DistilBert and MobileNetV2). For a fair assessment of the proposed loss function, we avoid datasets that would benefit from a two stage modelling procedure (object / expression / segment detection followed by classification) and instead turn to datasets, where the whole example is predictive of a label. This paper is thus a first assessment on the feasability of designing loss functions specifically for the multilabel setting based on statistical and information retrieval metrics.

%We present this problem as SIMPUL. \hvk{it is a bit confusing to me here that SIMPUL is presented as a problem, but as a framework in the title} Current solutions typically reframe the SIMPUL problem as a multiclass problem.

% \begin{itemize}
% \item \mdr{one sentence context}
% \item \mdr{one sentence problem statement}
% \item \mdr{one sentence what's wrong with current solutions}
% \item \mdr{one sentence our proposal}
% \item \mdr{one sentence the results achieved with our proposal}
% \item \mdr{one sentence why this matters}
% \end{itemize}
\end{abstract}
\keywords{Content analysis; Classification; Multiclass; Multilabel; Custom Loss \mdr{Keyword}}


\maketitle

\acresetall

\input{sections/01-introduction}
%\input{sections/02-task-definition}
% \input{sections/03-background}
\input{sections/04-method}
\input{sections/05-experimental-setup}
\input{sections/06-experimental-results}
% \input{sections/07-ablation-study}
\input{sections/07-related-work}
\input{sections/08-conclusions}

% \section*{Data and Code}
% To facilitate the reproducibility of the reported results, this work only made use of publicly available data and our experimental implementation is publicly available at \mdr{\url{where}}.

\begin{acks}
 This work was supported by many people.
 All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.
\end{acks}

\section*{APPENDIX}
\input{sections/02-task-definition}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
