% !TEX root = ../main.tex

\section{introduction}
\label{sec:org662677c}


Many real-world classification problems are challenging because of unclear (or overlapping) class-boundaries, subjectivity issues and disagreement between annotators.
For example, the movie \textit{Tenet} generated not just debates about its content, but also on which movie genre it belongs to. IMDB simultaneously categorizes it as \textit{action}, \textit{sci-fi}, and \textit{thriller}.\footnote{See \url{https://www.imdb.com/title/tt6723592/}.}
As a second example, a seminal machine learning publication that proposes to train with bigger batch sizes~\citep{bigBSArxiv} is categorized on \textit{arXiv} as \textit{Machine Learning (cs.LG)},
\textit{Computer Vision and Pattern Recognition (cs.CV)}, \textit{Distributed,
Parallel, and Cluster Computing (cs.DC)}, and \textit{Machine Learning
(stat.ML)}.\footnote{See \url{https://arxiv.org/abs/1711.00489}.}
These two examples are representative of a large class of classification problems that share several characteristics:
\begin{enumerate}[label=(\arabic*),leftmargin=*]
\item The possibility of assigning more than one label to a single instance is desirable (i.e., labels are not mutually exclusive).
\item The instance being labeled needs to be inspected or consumed in its entirety before a full set of class labels can be determined. E.g., it requires an entire viewing of the movie \textit{Tenet} to determine if the label \textit{romance} is appropriate, as it is arguably the underlying driver of the protagonists. In other words, it would be hard to isolate a simple characteristic of an instance that is uniquely predictive of a label. \hvk{I don't think this sentence explains what precedes it, these are two different characteristics (entire consumption and simple characteristic) The seconds paragraph of the background explains it better, I think}
\item The number of labels differs per instance, making the number of labels to assign at inference time unknown.
\end{enumerate}

\paragraph{Learning task}
We refer to learning tasks that share the three characteristics listed above as Full-instance, Multi-label Prediction for Unknown Label counts, or FIMPUL, for short.
Characteristic (1) is captured by the \emph{multi-label} predicate; characteristic (2) by \emph{full-instance}, and characteristic (3) by \emph{unknown label count}.
As we show in our experiments and the related work discussed below, FIMPUL learning tasks are very common in \ac{IR}. Document and text classification are often a FIMPUL task and have historically focused a lot of attention in \ac{IR}~\cite{IRClassStat, textCategorization, statTextCategorization, documentClassification}. Other \ac{IR} related examples are query classification~\cite{queryClassification}, image classification~\cite{imageClassification} and most recently the \textit{multimodal product classification and retrieval challenge} at SIGIR 2020~\cite{Amoualian2020SIGIR2E}. \hvk{@daan: this citation?}

\paragraph{Previous solutions to FIMPUL tasks}
To solve multi-label learning tasks, existing optimization frameworks are typically based on variations of the cross-entropy loss, with some recent advances dealing with specific aspects such as sparsity~\citep[see, e.g.,][]{focalLoss,tencent}.
Existing algorithmic solutions to deal with FIMPUL tasks can be divided into \emph{fit-data-to-algorithm} solutions, which map FIMPUL problems to a known problem formulation like multi-class uni-label classification, and \emph{fit-algorithm-to-data} solutions, which adapt existing classification algorithms for the problem at hand~\citep{multilabelMethods}. In the fit-data-to-algorithm solutions, cross-entropy losses are used at training time and thresholding is done at inference time to determine how many labels should be assigned to an instance. In the fit-algorithm-to-data solutions, elements of the learning algorithm are changed (such as the back propagation procedure or the tasks). An important shortcoming shared by both classes of solutions is the lack of a holistic approach for both label count and label prediction.

\paragraph{Our proposed solution to FIMPUL tasks}
We propose an alternative type of solution that is aimed at balancing prediction of label propensities and label count prediction. Our proposed solution, \solution (Confusion Matrix Metrics as Losses), is neither of the fit-algorithm-to-data type nor of the fit-data-to-algorithm type.
Instead, it is best characterized as an example of a \emph{design-algorithm-for-data} approach: the formulation of a loss function designed for the problem at hand, as opposed to using one existing optimization framework or optimizing over the sum of several loss functions.

\paragraph{Main contributions of the paper}
We propose a general mathematical formulation of FIMPUL tasks.
Our formulation encompasses different levels of complexity, from the classical cross-entropy loss up to the proposed loss function. We propose \solution. As a specific instance of the \solution, we introduce \emph{sigmoidF1}, an F1 score surrogate, with a sigmoid function acting as a surrogate thresholding step function.
\emph{sigmoidF1} allows for the use of the F1 metric that simultaneously optimizes for label prediction and label counts in a single task.
\emph{sigmoidF1} is benchmarked against loss functions commonly used in multi-label learning and other existing models that are closely related to the FIMPUL setting. We show that our custom losses improve predictions over the current state-of-the-art on several different metrics, across text and image classification tasks.

\paragraph{The remainder of the paper}
The remainder of this paper is structured as follows: first, we introduce our method and define a class of smooth loss functions for FIMPUL problems. Next, we detail our experimental setup and describe the datasets used in our experiments. After presenting the experimental results in the next section, we close the paper with conclusions and suggestions for future work.

% % \textbf{multi-class classification problems are hard}


% \paragraph{Problem statement}
% The examples given above in the domains of cinema and publishing have several things in common:
% \begin{enumerate*}[label=(\arabic*)]
% \item Labels such as \textit{thriller} and \textit{machine learning} are abstract and
% debatable concepts to a certain degree (as opposed to \textit{featured actor
% x}, \textit{featured in journal x}).
% \item The possibility of attributing more than one label to a single movie or a paper is desir{IR}able (i.e. labels are
% mutually inclusive: one example can have more than one label).
% \item The movie or paper as a whole needs to be looked at to label it. It requires an entire
% viewing of the movie \textit{Tenet} to determine if the label \textit{Romance}
% might not also be appropriate, as it is arguably the underlying driver of the
% protagonists. In other words, complex combinations of features in the movie
% are related to a label. In the contrary, it would be hard to isolate elements
% within these examples (such as a particular scene in a movie or a particular
% expression in a paper) as uniquely predictive of a single of their labels.
% \item The number of labels to attribute to each example is unknown at inference
% time.
% \end{enumerate*}

% In this paper we focus on such learning problems,  which we call \emph{Single-Instance Multilabel Prediction
% for Unknown Label counts} (SIMPUL).
% More precisely,
% \begin{itemize}
% \item \mdr{It's good to have a sharp definition of the problem space, whether it is SIMPUL or something else. And no, we do not need to sell it, we just need to identify it in a precise manner.}
% \item \mdr{a CONCISE definition of the problem, like in the paper by \citet{multilabelMethods}; no discussion, just definition.}
% \item \mdr{NO DISCUSSION, just a concise statement}
% \item \mdr{Include a comment that SIMPUL problems are very common in \ac{IR}, as we sho in the related work sectino below.}
% \end{itemize}

% \paragraph{Optimization frameworks to SIMPUL}
% As we explain in Section~\ref{section:background}, previous optimization frameworks for SIMPUL problems come in two flavors.
% \begin{itemize}
% \item flavor  1
% \item flavor 2
% \end{itemize}
% We introduce a new flavor,
% \begin{itemize}
% \item Why? One sentence about what's wrong with flavors 1 and 2
% \item Bring in the idea of confusion matrix metrics, etc. Just two sentences. No abstract stuff.
% \item What? One sentence about The New Thing.
% \end{itemize}

% \paragraph{Contributions}
% In this paper, we first propose a class of smooth loss functions that optimize
% learning in SIMPUL problems.
% \mdr{What does this mean? The generalization encompasses different levels
% of complexity, from the classical cross-entropy loss up to the proposed loss
% function.}
% \mdr{Isn't this too specific for the introduction; you haven't introduced this; how does it connect to confusion matrix metrics: We propose the \emph{sigmoidF1}: an F1 score surrogate, with a sigmoid function acting as a surrogate thresholding step function.} This allows for
% the use of the F1 metric which implicitly optimizes for label prediction and
% count simultaneously in a single task and is robust to outliers.
% \emph{sigmoidF1} and its adaptive \emph{SadF1} and Bayesian \emph{SBayesF1}
% counterparts are benchmarked against loss functions commonly used in
% multiclass learning and other existing models that are closely related to the
% SIMPUL setting.

% We show that our custom losses improve predictions over the
% current  state-of-the-art on several different metrics, across text
% (especially on the arXiv dataset which, to the best of our knowledge, is the
% first use since its publication in August 2020) and image related tasks.



% %%% Local Variables: %% mode: latex %% TeX-master: "../main" %% End:
