% !TEX root = ../main.tex

\section{Task Definition}

In this section, we use Figure~\ref{fig:tree} to further disambiguate the current method, by walking down its structure and explain why we avoid the left-leaning branches. We finish by showing how previous research focusing on problems down the tree tends to climb the tree back up to higher level of abstractions when looking for solutions.

Starting at the top of the tree, multiclass unilabel classification is often solved with common loss functions like cross entropy, mutinomial logit or focal loss. To the right, multiple labels can be assigned for the same example (e.g. movie genres, phenotypes). climbing down this time, multilabel tasks are often affiliated to image and text classification, where subsets of the original feature space can be singled out as predictive of a label (typically in object detection like with the COCO dataset  \cite{COCO} or the Amazon Rainforest Dataset\footnote{Available at \url{https://www.kaggle.com/c/planet-understanding-the-amazon-from-space}} \todo{others} \daan{a citation would be better here.}). Once elements are singled out, it is often trivial to allow each element to be only predictive of one label: the task often comes down to attributing a single label to an object or an expression. When it is technically possible to single out elements of an example that are predictive of a single label (or a lesser amount of labels), it is preferable to single-out rather than to predict given the entire image / text / audio~\cite{multiInstanceMultiLabel}.

In our setting, we deliberately deal with cases where it is not possible to single out elements. For example, expressions within a paper abstract, single notes within a song, or individual character stance within a movie poster can not be singled-out to be uniquely predictive of a single label. Rather, it is the interaction between the terms in the definition of the current study that could eventually classify this paper as a machine learning and information retrieval paper. Similarly, an actor holding a gun in a movie poster with otherwise jolly faces and background will probably not be an action/thriller movie, but rather a (dark) comedy. 

At the bottom of the tree, the situation where the number of labels $n_i$ to predict for each example is known a priori will deliberately be dodged. In that case, common information retrieval algorithms can retrieve ranks and thus $top_{n_i}$ predictions \todo{source}.
\daan{My feeling was that this was where we make the most significant contribution, in better distributing the loss over an unknown number of labels. If so, then this should be the gist of this section of text.}

We are left with the branch at the bottom right of the tree. Namely, we define the problem of single-instance multilabel learning for varying amount of labels. The strength of the proposed method is to 

Note that Figure~\ref{fig:tree} could be further divided into different branches starting from the bottom right corner. In particular, frameworks that study the relationships between labels like holistic label learning (as seen for image \cite{holisticImageDescriptors,holisticLungs} and video dataset \cite{holisticVideoData} \todo{read these}) and hierarchical label learning~\cite{activeLearningMultiLabel, HARAM} are left out of the picture, in order to focus on the general MSILUL formulation. \daan{MSILUL? Earlier acronym?}

We now briefly discuss the \emph{climbing-up} phenomenon described at the beginning of this section. To allow the use of existing differentiable loss fonctions, previous research papers tend to re-frame a problem at the bottom of the tree into models that learn for (I) multi-instance multiclass (as described above, with the COCO dataset as an example of isolation of features \cite{COCO}), (II) single-instance multiclass prediction \cite{multiclass} (III) single-instance multilabel prediction with fixed label count~\cite{threshForF1}. In other terms this relates to problem transformation, further detailed in the next section.

\daan{I am not very convinced by this section. I can see how the three helped shaped your thoughts, but let's discuss whether it helps sell the paper.}



% Similarly, recent research has shown that the singled-out elements can be located in the abstract representations (embeddings) of the feature set and might individually predict a single true label (like GPT-3 \todo{source}) \todo{more examples}. This might also carry prospects of generalizability of the model \cite{generalization} \todo{elaborate}.

% But for now, in certain retrieval tasks such as scientific journal tagging, the effect of sub-entities (either expressions in the text or single features in the embedding space) on the prediction of each label remains hard to assess. Instead we propose single-instance multilabel learning for varying amount of labels, with a focus on custom loss functions.







% In this section we provide a formal definition of the uni-instance multiclass multilabel problem with a varying number of labels on which we focus in this paper.
% \begin{itemize}
% \item Give a precise, formal definition of the problem 
% \item If appropriate, indicate formally fixed label counts vs.\ varying label counts 
% \item If appropriate, indicate formally uni-instance vs multi-instance
% \item Give three example instances of the problem (you could be inspired by the datasets that we use later in the paper)
% \end{itemize}