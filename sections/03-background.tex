% !TEX root = ../main.tex

\section{Background}
\label{sec:org8c910ea}

\hvk{I have the feeling that this should not be a seperate background section,
but is more appropriate as a subsection in the introduction. For example, you
now have to explicitly mention why the dichotomy of problem trans. and alg.
adaption is important for your argument, while it probably flows more
naturally from the information that is in the introduction}

This section reviews background material to be able to introduce our proposed solution to the SIMPUL problem.

Multilabel learning can be divided into two fields: \emph{problem transformation} and \emph{algorithm adaptation} \cite{multilabelReview}. In the case of problem transformation, multilabel classification is reframed as a binary, multiclass classification or label ranking problem. In the case of algorithm adaptation, one tries to adapt multiclass algorithms to the problem. \daan{This distinction I like!}

\subsection{Problem transformation}
For the purpose of problem transformation, we define \(\mathcal{L}_{\text {multiclass}}\), a class of loss functions that minimize predictions in relative terms. Binary cross-entropy, logit and their variants, such as focal loss or hinge loss (deemed unstable \cite{focalLoss} \daan{seems too big of a point for just a sidenote}) are common choices when it comes to multiclass prediction. Cross-entropy loss can be formulated as \(\mathcal{L}_{\text {CE}}=-\sum \log \left(p_{i}\right)\) . Note that minimizing binary cross-entropy is equivalent to maximizing for log-likelihood \cite[Section 4.3.4]{Bishop}. More generally, the \emph{problem transformation} formulation amounts to minimizing the loss on a class of neural networks, such that
%
\begin{equation}
\underset{\mathcal{L}_{\text {multiclass}}} {\min} \mathcal{F}\left(\cdot ; \Theta; \mathcal{L}_{\text {multiclass}} (\mathbf{y}, \hat{\mathbf{y}}) \right),
\end{equation}
%

\subsection{Algorithm adaptation}
In the context of \emph{algorithm adaptation}, where the number of positive labels in the groundtruth is unknown a priori \daan{this is not a property of algo adapt per se, right?}, we aim to both obtain a propensity of each label being true and a prediction of the number of true labels:
%
\begin{equation}
\underset{\mathcal{L}_{\text {multiclass}}, \mathcal{L}_{\text {count}}} {\min} \mathcal{F}\left(\cdot ; \Theta; \mathcal{L}_{\text {multiclass}} (\mathbf{y}, \hat{\mathbf{y}}) + \lambda \mathcal{L}_{\text {count}} (\mathbf{n}, \hat{\mathbf{n}})\right),
\end{equation}
%
where \(n_i = \sum_j \mathds{1}_{\mathbf{y_i^j} = 1}\) is the count of positive labels per example. We thus impose a constraint for the retrieval of label counts. For example, a cross-entropy loss surrogate \daan{You never really introduced the idea of surrogates, did you? Why is it needed? What are the limitations? etc.} would penalize for the number of wrongly predicted labels \(\mathcal{L}_{\text {CE+N}}= \mathcal{L}_{\text {CE}} + \lambda (\sum tp / \sum p)\), with \(t p=\sum_{i \in Y^{+}} \mathds{1}_{\mathbf{p_i} \geq b}\) and \(b\) a threshold to be defined. With its multitask framework (predict label prediction propensity and label count) \cite{multitaskLabel} corresponds to that type of infrastructure. \todo{tencent loss}.

The latter formulation is most straightfoward but suffers from higher parametrization and the lack of modelling of the interactions between label counts and label prediction. To mitigate these issues, we propose a unified loss formulation, namely
%
\begin{equation}
\underset{\mathcal{L}_{\text {multitag}}} {\min} \mathcal{F}\left(\cdot ; \Theta; \mathcal{L}_{\text {multitag}} (\mathbf{y}, \hat{\mathbf{y}}, \mathbf{n}, \hat{\mathbf{n}}) \right),
\end{equation}
%
Although predictions and counts explicitly appear in that formulation, \(\mathcal{L}_{\text {multitag}}\) can optimize for both metrics implicitely (see proposed \emph{sigmoidF1} below).
\daan{Whoa, where does multitag all of a sudden come from? ;-) }



% (IV) uni-instance multilabel prediction with varying label count with post-training thresholding (V) redefine backpropagation for multilabel prediction \cite{multilabelBackprop} (VI) multitask learning \cite{multitaskLabel} (VII) custom loss function \cite{tencent}. This order reflects in ascending order how close modelling seem to fit the original task, which remains uni-instance multilabel learning with varying amounts of labels. \doubt{group them}


\todo{look at YOU ONLY TRAIN ONCE: LOSS-CONDITIONAL TRAINING OF DEEP NETWORKS}

\todo{cite stat learning}   \cite[p. 308-310]{statLearning}

% * our contribution

% In order to verify our hypotheses, we use multilabel examples, where it is arguably hard to distinguish which elements is predictive of the label. For example, movie posters where the whole context is important and not just facial expressions, title font.
