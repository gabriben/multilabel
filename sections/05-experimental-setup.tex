% !TEX root = ../main.tex

\section{datasets}
\label{sec:orgb44ba25}

sigmoidF1 is tested across different modalities, namely image, video, sound and text, with a focus on text: the most comparable research was on text data.

% \doubt{optional paragraph}
% In light of the problem definition leading to the sigmoidF1 framework in the introduction and in order to clearly delimit the proposed method, following are a few datasets that are not suitable for the task.


Among the three datasets used for benchmarking ML-NET \cite{multitaskLabel}, a cancer hallmark dataset is of multi-instance multilabel nature \cite{cancerHallmarks} \footnote{Available at \url{https://www.cl.cam.ac.uk/&sim;sb895/HoC.html}}: the research clearly describe a process of annotating several expressions within paper abstracts. The remaining two datasets for chemical exposure \cite{chemExposure} \footnote{Available at \url{https://figshare.com/articles/Corpus_and_Software/4668229}} and diagnosis codes assigment \cite{diagnosisCode} \footnote{Available at \url{https://physionet.org/works/ICD9CodingofDischargeSummaries}}, seem to fit to the entity wide multilabel definition but have a strong hierarchical nature. Although slightly out-of-scope, the three datasets above will be used for benchmarking, since they were used to test ML-NET, which is the state-of-the-art in \emph{algorithm adaptation} for text to the best of our knowledge.

For a broader scope in learning for text data, we also use the newly created \emph{Arxiv dataset} \footnote{Available at https://www.kaggle.com/Cornell-University/arxiv} with data on abstracts of 1.7 million open source articles and their categories (suitably mutually inclusive and of varying count per example).

In the vision domain, a dataset of movie posters \footnote{Labels available at https://tinyurl.com/y7ydyedu and prescraped images from IMDB at https://tinyurl.com/y7lfpvlx} and their genre is used. Similarly, labels are mutually inclusive and of varying count per example. It is arguable that is hard to single out elements in the image of a poster that define the genre of a movie. Rather it might be a combination of the title font, the background image, the presence of actors and specific objects such as cars, weapons etc. 




\todo{I removed all jpg's that are empty in the prescraped data. I could try to scrape the posters myself to see if I get more}

Another recently created dataset was made available for \emph{Large Scale Holistic Video Understanding} \cite{holisticVideoData} \footnote{Available at https://github.com/holistic-video-understanding/HVU-Dataset}, as defined in the introduction.

% Cancer can be described according to its complexity with different principles, named hallmarks cite:cancerHallmarks. A corpus of 1580 PubMed abstracts are manually annotated for 10 hallmarks. This is a multi-instance labelling task and will therefore not be used here.

% [[./images/cancerHallmarksAnnotation.jpg]]

% - Multilabel classification for text cite:toxicComments

% - Scenery dataset for images cite:dataScenery.

\todo{this is an ambitious number of datasets. Add longer description of each dataset, depending on which ones I keep: sample size, number of classes etc. see utils here: https://github.com/ashrefm/multi-label-soft-f1}

\doubt{cite Kaggle datasets formally instead of using links: https://www.kaggle.com/data/46091}

\doubt{add a music genre classification dataset, for which Vincent Koops at RTL could help train}


